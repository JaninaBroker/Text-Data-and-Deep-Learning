http://neuralnetworksanddeeplearning.com/chap1.html
- Two important types of artifical neuron: the perceptron and the sigmoid neuron
  PERCEPTRON
  -Takes multiple binary inputs and produces ont binary output
  output={0 if ∑jwjxj≤ threshold
         {1 if ∑jwjxj> threshold
  where x is a binary input and w is a weight, so x is 0 or 1 depending on if its weighted sum is less than or greater than some threshold.
  -- Pereceptrons can be thought of as method of weighing evidence to make decisions. 
  We can move the threshold rule to teh oter side of the inequality sign, and call it a bias: wx+b≤0 and wx+b>0. Think of the bias as measuring 
  how easy it is to get the perecptron to output a 1. big bias - high likelihood of 1. Negative bias - hard to "fire"; low likelihood of 1. 
  
  
- The standard learning algorithm for neural networks known as stochastic gradient descent.

***************
Neural Networks
-2 to 8 hidden layers make a neural network "Deep", while 1 makes it "Non-deep".
- Research suggests that neural networks increase in accuracy with the number of hidden layers. 
From "7 Types of Neural Network Activation Functions: How to Choose?" at misinglink.ai. See link below:
https://missinglink.ai/guides/neural-network-concepts/7-types-neural-network-activation-functions-right/?fbclid=IwAR2PanChf6VZtTnrcZdqVtMimeSwIaPs_BQyIL4foCF8epnhpM9_9HbGOs0
 

ACTIVATION FUNCTIONS
Mathematical functions that determine the output of a Neural Network. The activation function is a mathematical "gate" between 
the input feeding the current neuron and its output going to the next laeýer. The function is attached to each neuron in the network 
and determines whether it should be activated or not. Activation functions also help normlaize the output of eac neuron to a 
range between 1 and 0 or between -1 and 1. (from missinglink.ai, same article as above)


- Non linear activation functions include 
    ReLU (Rectified Linear Unit)
    Leaky ReLU
    Parametric ReLu
    Swish
    Sigmooid/Logistic
    TanH/Hyperbolic tangent
    Softmax
    (https://missinglink.ai/guides/neural-network-concepts/7-types-neural-network-activation-functions-right/)
    
    
    
